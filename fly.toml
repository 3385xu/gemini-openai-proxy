app = "gemini-openai-proxy"
primary_region = "lax"

[build]
dockerfile = "docker/bun.Dockerfile"

[env]

[processes]

[http_service]
internal_port = 8000
force_https = true
auto_stop_machines = true
auto_start_machines = true
min_machines_running = 0
processes = ["app"]
[http_service.concurrency]
type = "requests"
soft_limit = 200
hard_limit = 250

[[vm]]
cpu_kind = "shared"
cpus = 1
memory = "512MB"
